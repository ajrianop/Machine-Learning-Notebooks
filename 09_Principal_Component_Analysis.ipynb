{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMj9W2HoHhXMf3hEi7txrC0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajrianop/Machine-Learning-Notebooks/blob/main/09_Principal_Component_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PCA or Principal Components Analysis**"
      ],
      "metadata": {
        "id": "Hn1RD91xP8bY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have several problems that have a huge number of dimensions, so dimensionality reduction becomes necessary to distill higher dimensionality data while preserving variance as much as possible.\n",
        "\n",
        "One example where we can observe dimensionality reduction is K-Means, where the data is reduced down to k-dimensions.\n",
        "\n",
        "PCA (Principal Component Analysis) involves a high-level technique that utilizes linear algebra and probability theory. The idea behind PCA is to find the eigenvectors in the higher dimensionality space such that the hyperplanes associated with these vectors capture the most variance. This allows us to project the information onto these hyperplanes, which then serve as representations of our information with a smaller number of dimensions. The implementation of this technique is called Singular Value Decomposition (SVD)."
      ],
      "metadata": {
        "id": "8q2ErIC8P_DN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to work with the load_iris dataset, which can be found in the sklearn library. This dataset comprises samples of three different species of iris flowers, along with various measurements including sepal length, sepal width, petal length, and petal width.\n",
        "\n",
        "This dataset is commonly used for classification and clustering tasks in machine learning.\n"
      ],
      "metadata": {
        "id": "C-v614WCaHjV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yoCN4MGsP7zp"
      },
      "outputs": [],
      "source": []
    }
  ]
}